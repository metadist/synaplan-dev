# Synaplan - AI-Powered Knowledge Management System

AI-powered knowledge management with chat, document processing, and RAG (Retrieval-Augmented Generation).

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Git

### Installation

```bash
git clone <repository-url>
cd synaplan-dev
AUTO_DOWNLOAD_MODELS=true docker compose up -d
```

That's it! Docker Compose automatically:
- âœ… Starts Backend (Symfony + PHP 8.3) on port 8000
- âœ… Starts Frontend (Vue.js + Vite) on port 5173
- âœ… Creates environment files (`backend/.env.local`, `frontend/.env.docker`)
- âœ… Runs database migrations
- âœ… Seeds test users and fixtures
- âœ… Downloads AI models in background (if AUTO_DOWNLOAD_MODELS=true)
- âœ… System ready in ~20 seconds (models continue downloading in background)

**Check model download progress:**
```bash
docker compose logs -f backend | grep -i "model\|background"
```

## ğŸŒ Access

| Service | URL | Description |
|---------|-----|-------------|
| Frontend | http://localhost:5173 | Vue.js Web App |
| Backend API | http://localhost:8000 | Symfony REST API |
| phpMyAdmin | http://localhost:8082 | Database Management |
| MailHog | http://localhost:8025 | Email Testing |
| Ollama | http://localhost:11435 | AI Models API |

## ğŸ‘¤ Test Users

| Email | Password | Level |
|-------|----------|-------|
| admin@synaplan.com | admin123 | BUSINESS |
| demo@synaplan.com | demo123 | PRO |
| test@example.com | test123 | NEW |

## ğŸ§  RAG System

The system includes a full RAG (Retrieval-Augmented Generation) pipeline:

- **Upload**: Multi-level processing (Extract Only, Extract + Vectorize, Full Analysis)
- **Extraction**: Tika (documents), Tesseract OCR (images), Whisper (audio)
- **Vectorization**: bge-m3 embeddings (1024 dimensions) via Ollama
- **Storage**: Native MariaDB VECTOR type with VEC_DISTANCE_COSINE similarity search
- **Search**: Semantic search UI with configurable thresholds and group filtering
- **Sharing**: Private by default, public sharing with optional expiry

## ğŸ“ Project Structure

```
synaplan-dev/
â”œâ”€â”€ _devextras/          # Development extras
â”œâ”€â”€ _docker/             # Docker configurations
â”‚   â”œâ”€â”€ backend/         # Backend Dockerfile & scripts
â”‚   â””â”€â”€ frontend/        # Frontend Dockerfile & nginx
â”œâ”€â”€ backend/             # Symfony Backend (PHP 8.3)
â”œâ”€â”€ frontend/            # Vue.js Frontend
â””â”€â”€ docker-compose.yml   # Main orchestration
```

## âš™ï¸ Environment Configuration

Environment files are auto-generated on first start:
- `backend/.env.local` (auto-created by backend container, only if not exists)
- `frontend/.env.docker` (auto-created by frontend container)

**Note:** `.env.local` is never overwritten. To reset: delete the file and restart container.

Example files provided:
- `backend/.env.docker.example` (reference)
- `frontend/.env.docker.example` (reference)

## ğŸ› ï¸ Development

```bash
# View logs
docker compose logs -f

# Restart services
docker compose restart backend
docker compose restart frontend

# Reset database (deletes all data!)
docker compose down -v
docker compose up -d

# Run migrations
docker compose exec backend php bin/console doctrine:migrations:migrate

# Install packages
docker compose exec backend composer require <package>
docker compose exec frontend npm install <package>
```

## ğŸ¤– AI Models

Models are downloaded **on-demand** when first used:
- **mistral:7b** - Main chat model (4.1 GB) - Downloaded on first chat
- **bge-m3** - Embedding model for RAG (2.2 GB) - Downloaded when using document search

### Pre-download Models (Recommended)

To download models during startup (in background):
```bash
AUTO_DOWNLOAD_MODELS=true docker compose up -d
```

**The backend starts immediately** while models download in parallel. Monitor progress:
```bash
docker compose logs -f backend
```

You'll see messages like:
- `[Background] â³ Model 'mistral:7b' download in progress...`
- `[Background] âœ… Model 'mistral:7b' downloaded successfully!`

## âœ¨ Features

- âœ… **AI Chat**: Multiple providers (Ollama, OpenAI, Anthropic, Groq, Gemini)
- âœ… **RAG System**: Semantic search with MariaDB VECTOR + bge-m3 embeddings (1024 dim)
- âœ… **Document Processing**: PDF, Word, Excel, Images (Tika + OCR)
- âœ… **Audio Transcription**: Whisper.cpp integration
- âœ… **File Management**: Upload, share (public/private), organize with expiry
- âœ… **App Modes**: Easy mode (simplified) and Advanced mode (full features)
- âœ… **Security**: Private files by default, secure sharing with tokens
- âœ… **Multi-user**: Role-based access with JWT authentication
- âœ… **Responsive UI**: Vue.js 3 + TypeScript + Tailwind CSS

## ğŸ“„ License

See [LICENSE](LICENSE)
